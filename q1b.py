# -*- coding: utf-8 -*-
"""Ass4q1bHOG.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1stfBkmfWVqLZgZuAH_aFfR-dF3JxSJan
"""

import torch
import numpy as np
from skimage.filters import gabor
from skimage import data, io
from matplotlib import pyplot as plt
from skimage.feature import hog
import sys

def getData(xPath):
  x_in = np.genfromtxt(xPath ,delimiter=",")
  x = x_in[:,1:]
  y = x_in[:,0]
  # x = x/255
  return x,y
xTrain,yTrain = getData(sys.argv[1])
xTest,yTest = getData(sys.argv[2])
r = len(np.unique(yTrain))
n = np.shape(xTrain)[1]
numFeatures = n
m = np.shape(xTrain)[0]

model = torch.nn.Sequential(
        torch.nn.Linear(in_features=1296, out_features=100),
        torch.nn.ReLU(),
        torch.nn.Linear(in_features=100, out_features=r)
    )
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

hog_train_x = []
for i in range(len(xTrain)):
  h = hog(xTrain[i].reshape((48,48)))
  hog_train_x.append(h.reshape((1,-1)))

hog_train_x = np.concatenate( hog_train_x, axis=0 )
# print(hog_train_x.shape)

xTrain = torch.tensor(hog_train_x,dtype=torch.float).to(device)
yTrain = torch.tensor(yTrain,dtype=torch.long).to(device)

import torch
import torch.nn as nn
optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # stochastic gradient descent
criterion = torch.nn.CrossEntropyLoss() 
model = model.to(device)
EPOCHS = 50000
early_stop = 0
prevLoss = 0
M = 100
e = 0
while(e<EPOCHS and early_stop<10):
  for i in range(0,int(m/M)):
    # optimizer.zero_grad()
    x_train = xTrain[(i)*M:(i)*M + M,:]
    y_train = yTrain[i*M:i*M + M]
    optimizer.zero_grad()
    y_predicted = model(x_train)
    loss = criterion(y_predicted, y_train)
    if(abs(prevLoss - loss.item()) < 0.000001 and e>0):
      early_stop+=1
    loss.backward()  
    prevLoss = loss.item()  
    with torch.no_grad():
      for p in model.parameters():
        p -= p.grad * 0.02
    model.zero_grad()
  e+=1
  # if e % 100 == 0:
    # print('Epoch: {}  Loss: {} '.format(e, loss.item()))

hog_test_x = []
for i in range(len(xTest)):
  h = hog(xTest[i].reshape((48,48)))
  hog_test_x.append(h.reshape((1,-1)))
hog_test_x = np.concatenate( hog_test_x, axis=0 )
xTest = torch.tensor(hog_test_x,dtype=torch.float).to(device)
yTest = torch.tensor(yTest,dtype=torch.long).to(device)
y_predicted = model(xTest)
# print(y_predicted)
y_predicted = torch.argmax(y_predicted,dim=1)

def write_predictions(fname, arr):
    np.savetxt(fname, arr, fmt="%d", delimiter="\n")
# np.savetxt(sys.argv[3], y_predicted, fmt="%d", delimiter="\n")
write_predictions(str(sys.argv[3]),y_predicted.cpu())# print(y_predicted)
# # print(yTrain)
# # print(yTrain.size())
# correct = 0
# for i in range(len(y_predicted)):
#   if yTest[i] == y_predicted[i]:
#     correct += 1
# # yTrain = yTrain.view(m,-1)
# # correct += (y_predicted == yTrain).float().sum()
# # print(correct)
# accuracy = 100 * correct / ((xTest.size)(0))
# print("Test Accuracy = {}".format(accuracy))


# confusion_matrix = torch.zeros(7, 7)
# y_predicted = model(xTest)
# # print(y_predicted)
# y_predicted = torch.argmax(y_predicted,dim=1)
# # # print(y_predicted)
# # print(yTrain)
# # print(yTrain.size())
# correct = 0
# for t, p in zip(yTest.view(-1), y_predicted.view(-1)):
#   confusion_matrix[t.long(), p.long()] += 1
# print(confusion_matrix.int())

# y_predicted = model(xTrain)
# # print(y_predicted)
# y_predicted = torch.argmax(y_predicted,dim=1)
# # print(y_predicted)
# # print(yTrain)
# # print(yTrain.size())
# correct = 0
# for i in range(len(y_predicted)):
#   if yTrain[i] == y_predicted[i]:
#     correct += 1
# # yTrain = yTrain.view(m,-1)
# # correct += (y_predicted == yTrain).float().sum()
# # print(correct)
# accuracy = 100 * correct / ((xTrain.size)(0))
# print("Train ccuracy = {}".format(accuracy))

